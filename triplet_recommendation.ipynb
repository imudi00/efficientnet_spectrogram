{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53eab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ÏÖÄ 1: Î™®Îìà import Î∞è Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "data_root = \"./data\"\n",
    "song_ids = sorted([d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))])\n",
    "random.seed(42)\n",
    "random.shuffle(song_ids)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(song_ids) * split_ratio)\n",
    "train_ids = song_ids[:split_index]\n",
    "val_ids = song_ids[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a98a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ÏÖÄ 2: EfficientNet ÏûÑÎ≤†Îî© Î™®Îç∏ Ï†ïÏùò\n",
    "class EfficientNetEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_size=128):\n",
    "        super().__init__()\n",
    "        self.base_model = models.efficientnet_b0(pretrained=True)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.features = self.base_model.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.embedding = nn.Linear(1280, embedding_size)\n",
    "        self.l2_norm = nn.functional.normalize\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.embedding(x)\n",
    "        x = self.l2_norm(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ÏÖÄ 3: Triplet Dataset ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, root_dir, song_ids=None, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        if song_ids is None:\n",
    "            self.song_dirs = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        else:\n",
    "            self.song_dirs = [os.path.join(root_dir, d) for d in song_ids]\n",
    "        self.data = []\n",
    "        for song_dir in self.song_dirs:\n",
    "            images = [f for f in os.listdir(song_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "            if len(images) >= 2:\n",
    "                self.data.append((song_dir, images))\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(images) for _, images in self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        anchor_song_idx = random.randint(0, len(self.data) - 1)\n",
    "        anchor_song_dir, anchor_images = self.data[anchor_song_idx]\n",
    "        anchor_img_name = random.choice(anchor_images)\n",
    "        positive_img_name = anchor_img_name\n",
    "        while positive_img_name == anchor_img_name:\n",
    "            positive_img_name = random.choice(anchor_images)\n",
    "        negative_song_idx = anchor_song_idx\n",
    "        while negative_song_idx == anchor_song_idx:\n",
    "            negative_song_idx = random.randint(0, len(self.data) - 1)\n",
    "        negative_song_dir, negative_images = self.data[negative_song_idx]\n",
    "        negative_img_name = random.choice(negative_images)\n",
    "\n",
    "        anchor_img = Image.open(os.path.join(anchor_song_dir, anchor_img_name)).convert('RGB')\n",
    "        positive_img = Image.open(os.path.join(anchor_song_dir, positive_img_name)).convert('RGB')\n",
    "        negative_img = Image.open(os.path.join(negative_song_dir, negative_img_name)).convert('RGB')\n",
    "        if self.transform:\n",
    "            anchor_img = self.transform(anchor_img)\n",
    "            positive_img = self.transform(positive_img)\n",
    "            negative_img = self.transform(negative_img)\n",
    "        return anchor_img, positive_img, negative_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ÏÖÄ 4: Ï†ÑÏ≤òÎ¶¨, Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è Îç∞Ïù¥ÌÑ∞Î°úÎçî ÏÑ§Ï†ï\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = TripletDataset(root_dir=data_root, song_ids=train_ids, transform=transform)\n",
    "val_dataset = TripletDataset(root_dir=data_root, song_ids=val_ids, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ÏÖÄ 5: ÌïôÏäµ Î∞è Í≤ÄÏ¶ù Ìï®Ïàò\n",
    "def train_triplet(model, data_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for anchor, positive, negative in data_loader:\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        anchor_embed = model(anchor)\n",
    "        positive_embed = model(positive)\n",
    "        negative_embed = model(negative)\n",
    "        loss = loss_fn(anchor_embed, positive_embed, negative_embed)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_triplet(model, data_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for anchor, positive, negative in data_loader:\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "        anchor_embed = model(anchor)\n",
    "        positive_embed = model(positive)\n",
    "        negative_embed = model(negative)\n",
    "        loss = loss_fn(anchor_embed, positive_embed, negative_embed)\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ÏÖÄ 6: ÌïôÏäµ Ïã§Ìñâ\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EfficientNetEmbedding(embedding_size=128).to(device)\n",
    "loss_fn = nn.TripletMarginLoss(margin=1.0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_triplet(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_loss = validate_triplet(model, val_loader, loss_fn, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4e69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ÏÖÄ 7: ÏûÑÎ≤†Îî© Ï∂îÏ∂ú Î∞è Ï∂îÏ≤ú Ìï®Ïàò\n",
    "def extract_embeddings(model, inputs, device, batch_size=64):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        if isinstance(inputs, DataLoader):\n",
    "            for batch in inputs:\n",
    "                batch = batch.to(device)\n",
    "                emb = model(batch)\n",
    "                embeddings.append(emb.cpu().numpy())\n",
    "            embeddings = np.vstack(embeddings)\n",
    "        else:\n",
    "            inputs = inputs.to(device)\n",
    "            emb = model(inputs)\n",
    "            embeddings = emb.cpu().numpy()\n",
    "    return embeddings\n",
    "\n",
    "def recommend_topk(query_embedding, gallery_embeddings, gallery_ids, topk=5):\n",
    "    sims = cosine_similarity(query_embedding.reshape(1, -1), gallery_embeddings).flatten()\n",
    "    topk_idx = sims.argsort()[::-1][:topk]\n",
    "    return [(gallery_ids[i], sims[i]) for i in topk_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0fd86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ÏÖÄ 8: Ï∂îÎ°† Î∞è Ï∂îÏ≤ú Ïã§Ìñâ\n",
    "gallery_ids = train_ids + val_ids\n",
    "gallery_dataset = TripletDataset(root_dir=data_root, song_ids=gallery_ids, transform=transform)\n",
    "gallery_loader = DataLoader(gallery_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "gallery_embeddings = extract_embeddings(model, gallery_loader, device)\n",
    "np.save(\"gallery_embeddings.npy\", gallery_embeddings)\n",
    "\n",
    "test_img_path = \"./test_query.png\"\n",
    "test_img = Image.open(test_img_path).convert('RGB')\n",
    "test_img_tensor = transform(test_img).unsqueeze(0)\n",
    "query_embedding = extract_embeddings(model, test_img_tensor, device)\n",
    "\n",
    "gallery_id_names = [os.path.basename(d) for d, _ in gallery_dataset.data]\n",
    "recommendations = recommend_topk(query_embedding, gallery_embeddings, gallery_id_names, topk=5)\n",
    "\n",
    "print(\"üéß Ï∂îÏ≤ú Í≤∞Í≥º:\")\n",
    "for i, (song_id, score) in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. Í≥° ID: {song_id} (Ïú†ÏÇ¨ÎèÑ: {score:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
